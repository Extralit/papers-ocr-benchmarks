{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4243689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import ocrmypdf\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from pymupdf4llm import to_markdown, IdentifyHeaders\n",
    "import re\n",
    "\n",
    "# Create output directory\n",
    "Path(\"output_markdown\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f6d8e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_scanned_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    for page in doc:\n",
    "        if page.get_text().strip():\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f702455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocr(input_path, output_path):\n",
    "    print(\"üîÅ Running OCRmyPDF...\")\n",
    "    ocrmypdf.ocr(\n",
    "        input_file=input_path,\n",
    "        output_file=output_path,\n",
    "        rotate_pages=True,\n",
    "        deskew=True,\n",
    "        force_ocr=True,\n",
    "        skip_text=True\n",
    "    )\n",
    "    print(f\"‚úÖ OCR complete: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5ad8e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_heading_hierarchy(md_text):\n",
    "    lines = md_text.split('\\n')\n",
    "    updated_lines = []\n",
    "    for line in lines:\n",
    "        match = re.match(r'^(#+)\\s+(.*)', line)\n",
    "        if match:\n",
    "            hashes, content = match.groups()\n",
    "            # Promote/demote based on content\n",
    "            if len(hashes) == 1:\n",
    "                hashes = '##'\n",
    "            elif len(hashes) == 2:\n",
    "                if any(word in content.lower() for word in ['mortality', 'knock-down', 'resistance', 'vector', 'prevalence']):\n",
    "                    hashes = '###'\n",
    "            line = f\"{hashes} {content}\"\n",
    "        updated_lines.append(line)\n",
    "    return '\\n'.join(updated_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d584db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced version with debugging\n",
    "def extract_markdown_with_hierarchy(pdf_path, md_output_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    toc = doc.get_toc()\n",
    "    \n",
    "    if toc:\n",
    "        print(f\"üìã Found TOC with {len(toc)} entries\")\n",
    "        for i, (level, title, page) in enumerate(toc[:3]):\n",
    "            print(f\"  Level {level}: '{title}' (page {page})\")\n",
    "        hdr_info = toc\n",
    "    else:\n",
    "        print(\"üîç No TOC found, using automatic header detection\")\n",
    "        hdr_info = IdentifyHeaders(doc)\n",
    "        \n",
    "        # Debug: Show what headers were identified\n",
    "        if hasattr(hdr_info, 'get_header_id'):\n",
    "            print(\"üìù Identified headers:\")\n",
    "            for page_num in range(min(3, len(doc))):  # Check first 3 pages\n",
    "                page = doc[page_num]\n",
    "                blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "                for block in blocks:\n",
    "                    if \"lines\" in block:\n",
    "                        for line in block[\"lines\"]:\n",
    "                            for span in line[\"spans\"]:\n",
    "                                if hdr_info.get_header_id(span, page=page):\n",
    "                                    print(f\"  Page {page_num+1}: '{span['text'].strip()}'\")\n",
    "    \n",
    "    # Generate markdown with proper hierarchy\n",
    "    markdown_text = to_markdown(doc, hdr_info=hdr_info)\n",
    "    \n",
    "    with open(md_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(markdown_text)\n",
    "    \n",
    "    print(f\"‚úÖ Markdown saved: {md_output_path}\")\n",
    "    return markdown_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "582ee8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_pipeline(pdf_path):\n",
    "    filename = Path(pdf_path).stem\n",
    "    output_dir = Path(\"output_markdown\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    temp_dir = Path(\"temp_ocr\")\n",
    "    temp_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    ocr_path = temp_dir / f\"{filename}_ocr.pdf\"\n",
    "    md_output = output_dir / f\"{filename}.md\"\n",
    "\n",
    "    print(f\"üîç Processing PDF: {pdf_path}\")\n",
    "    scanned = is_scanned_pdf(pdf_path)\n",
    "\n",
    "    if scanned:\n",
    "        print(\"üßæ Detected scanned PDF\")\n",
    "        run_ocr(pdf_path, ocr_path)\n",
    "        used_pdf = ocr_path\n",
    "    else:\n",
    "        print(\"üìÑ Detected born-digital PDF\")\n",
    "        used_pdf = Path(pdf_path)\n",
    "\n",
    "    return extract_markdown_with_hierarchy(used_pdf, md_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d5d9bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing PDF: pdfs/Allossogbe_et_al_2017_Mal_J.pdf\n",
      "üìÑ Detected born-digital PDF\n",
      "üìã Found TOC with 36 entries\n",
      "  Level 1: 'WHO cone bio-assays of¬†classical and¬†new-generation long-lasting insecticidal nets call for¬†innovative insecticides targeting the knock-down resistance mechanism in¬†Benin' (page 1)\n",
      "  Level 2: 'Abstract ' (page 1)\n",
      "  Level 3: 'Background: ' (page 1)\n",
      "‚úÖ Markdown saved: output_markdown\\Allossogbe_et_al_2017_Mal_J.md\n"
     ]
    }
   ],
   "source": [
    "test_pdf = \"pdfs/Allossogbe_et_al_2017_Mal_J.pdf\"\n",
    "markdown_text = process_pdf_pipeline(test_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2d69b3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOI: None\n"
     ]
    }
   ],
   "source": [
    "## DOI if in metadata\n",
    "\n",
    "doc = fitz.open(test_pdf)\n",
    "doi = doc.metadata.get(\"doi\", None)\n",
    "print(\"DOI:\", doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "35f63b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOI from text: 10.1186/s12936-017-1727-x\n"
     ]
    }
   ],
   "source": [
    "## Added DOI if not in metadata\n",
    "\n",
    "doc = fitz.open(test_pdf)\n",
    "first_page_text = doc[0].get_text()\n",
    "match = re.search(r'(10\\.\\d{4,9}/[-._;()/:A-Z0-9]+)', first_page_text, re.I)\n",
    "doi = match.group(1) if match else None\n",
    "print(\"DOI from text:\", doi)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
